{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PtnR0fWqm7zC"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "develop a model based on the onnx file in model/model.onnx \n",
        "\n",
        "Note:\n",
        "    - initialize the convolutions layer with uniform xavier\n",
        "    - initialize the linear layer with a normal distribution (mean=0.0, std=1.0)\n",
        "    - initialize all biases with zeros\n",
        "    - use batch norm wherever is relevant\n",
        "    - use random seed 8\n",
        "    - use default values for anything unspecified\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "torch.manual_seed(8)    # DO NOT MODIFY!\n",
        "np.random.seed(8)   # DO NOT MODIFY!\n",
        "\n",
        "\n",
        "# write your code here ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "model = onnx.load('/content/model.onnx')"
      ],
      "metadata": {
        "id": "zpB-3PKs0Et6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a convolution neural network\n",
        "batch_size=1\n",
        "input_channels=3\n",
        "image_height=160\n",
        "image_width=320\n",
        "input_shape=[batch_size,input_channels, image_height, image_width]\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act1 = nn.Sigmoid()\n",
        " \n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act2 = nn.Sigmoid()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act3 = nn.Sigmoid()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act4 = nn.Sigmoid()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 64, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act5 = nn.Sigmoid()\n",
        "\n",
        "        self.conv6 = nn.Conv2d(64, 64, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act6 = nn.Sigmoid()\n",
        "\n",
        "        self.conv7 = nn.Conv2d(64, 64, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act7 = nn.Sigmoid()\n",
        "\n",
        "        self.conv8 = nn.Conv2d(64, 64, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act8 = nn.Sigmoid()\n",
        "\n",
        "        self.conv9 = nn.Conv2d(64, 64, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act9 = nn.Sigmoid()\n",
        "\n",
        "        self.conv10 = nn.Conv2d(64, 128, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act10 = nn.Sigmoid()\n",
        "\n",
        "\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "       \n",
        "        x = self.act2(self.conv2(x))\n",
        "\n",
        "        x = self.act3(self.conv2(x))\n",
        "\n",
        "        x = self.act4(self.conv2(x))\n",
        "     \n",
        "        return x\n",
        " "
      ],
      "metadata": {
        "id": "N1O9rWNLrGes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v4Uzaz1gaWeC"
      }
    }
  ]
}